{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "labeled-venture",
   "metadata": {},
   "source": [
    "```{figure} ../images/banner.png\n",
    "---\n",
    "align: center\n",
    "name: banner\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-statement",
   "metadata": {},
   "source": [
    "# Chapter 11 : JSON Column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strategic-darwin",
   "metadata": {},
   "source": [
    "## Chapter Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plastic-couple",
   "metadata": {},
   "source": [
    "- Various data operations on columns containing Json string. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apparent-custody",
   "metadata": {},
   "source": [
    "## Chapter Outline\n",
    "\n",
    "- [1. How to deal with JSON string column?](#1)\n",
    "    - [1a. How to create a  spark dataframe with a JSON string column ?](#2)\n",
    "    - [1b. How to infer a schema in DDL format from  a JSON string column ?](#3)\n",
    "    - [1c. How to extract elements from JSON column ?](#4)\n",
    "    - [1d. How to convert a data frame to JSON string?](#5)\n",
    "    - [1e. How to convert JSON string column into StructType column?](#6)\n",
    "    - [1f. How to convert JSON string column into MapType column?](#7)\n",
    "    - [1g. How to convert JSON string column into ArrayType column?](#8)\n",
    "    - [1h. How to convert StructType/MapType/ArrayType  column into JSON string?](#9)  \n",
    "    - [1i. How to extract JSON object from a JSON  string column?](#10)\n",
    "    - [1j. How to extract JSON objects based on list of field names?](#11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "passing-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n",
    "from IPython.display import display_html\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "def display_side_by_side(*args):\n",
    "    html_str=''\n",
    "    for df in args:\n",
    "        html_str+=df.to_html(index=False)\n",
    "        html_str+= \"\\xa0\\xa0\\xa0\"*10\n",
    "    display_html(html_str.replace('table','table style=\"display:inline\"'),raw=True)\n",
    "space = \"\\xa0\" * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "tamil-biodiversity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    var skip = [];\n",
       "    if (window.requirejs) {\n",
       "      require([], function() {\n",
       "      })\n",
       "    }\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      if (skip.indexOf(url) >= 0) { on_load(); continue; }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "\tif (!js_urls.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\", \"https://unpkg.com/@holoviz/panel@^0.10.3/dist/panel.min.js\"];\n",
       "  var css_urls = [\"https://unpkg.com/@holoviz/panel@0.10.3/dist/css/alerts.css\", \"https://unpkg.com/@holoviz/panel@0.10.3/dist/css/card.css\", \"https://unpkg.com/@holoviz/panel@0.10.3/dist/css/widgets.css\", \"https://unpkg.com/@holoviz/panel@0.10.3/dist/css/markdown.css\", \"https://unpkg.com/@holoviz/panel@0.10.3/dist/css/json.css\", \"https://unpkg.com/@holoviz/panel@0.10.3/dist/css/dataframe.css\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      inject_raw_css(\"\\ndiv.special_table + table, th, td {\\n  border: 3px solid orange;\\n}\\n\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      inject_raw_css(\"\\ndiv.special_table + table, th, td {\\n  border: 3px solid orange;\\n}\\n\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      inject_raw_css(\"\\ndiv.special_table + table, th, td {\\n  border: 3px solid orange;\\n}\\n\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      inject_raw_css(\"\\ndiv.special_table + table, th, td {\\n  border: 3px solid orange;\\n}\\n\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      inject_raw_css(\"\\ndiv.special_table + table, th, td {\\n  border: 3px solid orange;\\n}\\n\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      inject_raw_css(\"\\ndiv.special_table + table, th, td {\\n  border: 3px solid orange;\\n}\\n\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      inject_raw_css(\"\\ndiv.special_table + table, th, td {\\n  border: 3px solid orange;\\n}\\n\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      require([], function() {\n      })\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) >= 0) { on_load(); continue; }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n\tif (!js_urls.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\", \"https://unpkg.com/@holoviz/panel@^0.10.3/dist/panel.min.js\"];\n  var css_urls = [\"https://unpkg.com/@holoviz/panel@0.10.3/dist/css/alerts.css\", \"https://unpkg.com/@holoviz/panel@0.10.3/dist/css/card.css\", \"https://unpkg.com/@holoviz/panel@0.10.3/dist/css/widgets.css\", \"https://unpkg.com/@holoviz/panel@0.10.3/dist/css/markdown.css\", \"https://unpkg.com/@holoviz/panel@0.10.3/dist/css/json.css\", \"https://unpkg.com/@holoviz/panel@0.10.3/dist/css/dataframe.css\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      inject_raw_css(\"\\ndiv.special_table + table, th, td {\\n  border: 3px solid orange;\\n}\\n\");\n    },\n    function(Bokeh) {\n      inject_raw_css(\"\\ndiv.special_table + table, th, td {\\n  border: 3px solid orange;\\n}\\n\");\n    },\n    function(Bokeh) {\n      inject_raw_css(\"\\ndiv.special_table + table, th, td {\\n  border: 3px solid orange;\\n}\\n\");\n    },\n    function(Bokeh) {\n      inject_raw_css(\"\\ndiv.special_table + table, th, td {\\n  border: 3px solid orange;\\n}\\n\");\n    },\n    function(Bokeh) {\n      inject_raw_css(\"\\ndiv.special_table + table, th, td {\\n  border: 3px solid orange;\\n}\\n\");\n    },\n    function(Bokeh) {\n      inject_raw_css(\"\\ndiv.special_table + table, th, td {\\n  border: 3px solid orange;\\n}\\n\");\n    },\n    function(Bokeh) {\n      inject_raw_css(\"\\ndiv.special_table + table, th, td {\\n  border: 3px solid orange;\\n}\\n\");\n    },\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            console.log(message)\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        comm.open();\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        }) \n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import panel as pn\n",
    "\n",
    "css = \"\"\"\n",
    "div.special_table + table, th, td {\n",
    "  border: 3px solid orange;\n",
    "}\n",
    "\"\"\"\n",
    "pn.extension(raw_css=[css])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-huntington",
   "metadata": {},
   "source": [
    "<a id='1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-connectivity",
   "metadata": {},
   "source": [
    "##  Chapter Outline - Gallery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-password",
   "metadata": {},
   "source": [
    "<div class=\"special_table\"></div>\n",
    "\n",
    "click on  | any image\n",
    "---: |:--- \n",
    "[![alt](img/chapter11/1.png)](#2)| [![alt](img/chapter11/2.png)](#3)\n",
    "[![alt](img/chapter11/3.png)](#4)| [![alt](img/chapter11/4.png)](#5)\n",
    "[![alt](img/chapter11/5.png)](#6)| [![alt](img/chapter11/6.png)](#7)\n",
    "[![alt](img/chapter11/7.png)](#6)| [![alt](img/chapter11/8.png)](#7)\n",
    "[![alt](img/chapter11/9.png)](#6)| [![alt](img/chapter11/10.png)](#7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-national",
   "metadata": {},
   "source": [
    "<a id='2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-blowing",
   "metadata": {},
   "source": [
    "## 1a. How to create a  spark dataframe with a JSON string column ?\n",
    "\n",
    "\n",
    "\n",
    "```{figure} img/chapter11/1.png\n",
    "---\n",
    "align: center\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "advanced-charger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|json_string                                                                                                                                                   |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|{\"me\": {\"name\":\"tony\"},\"myfamily_heirarchy\":{\"myfather\":\"mike\",\"myfather_childs\": [\"me\",\"kent\"],\"my_childs\":{\"name\": \"susan\",\"susan_childs\":{\"name\":\"suzy\"}}}}|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "json_string = '{\"me\": {\"name\":\"tony\"},\"myfamily_heirarchy\":{\"myfather\":\"mike\",\"myfather_childs\": [\"me\",\"kent\"],\"my_childs\":{\"name\": \"susan\",\"susan_childs\":{\"name\":\"suzy\"}}}}'\n",
    "rdd = spark.sparkContext.parallelize([json_string])\n",
    "df_json = spark.createDataFrame([(json_string,)],[\"json_string\"])\n",
    "df_json.show(1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "significant-petroleum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- json_string: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_json.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-monaco",
   "metadata": {},
   "source": [
    "<a id='3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-foundation",
   "metadata": {},
   "source": [
    "## 1b. How to infer a schema in DDL format from  a JSON string column ?\n",
    "\n",
    "\n",
    "```{figure} img/chapter11/2.png\n",
    "---\n",
    "align: center\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-partnership",
   "metadata": {},
   "source": [
    "Lets first understand the syntax\n",
    "\n",
    "```{admonition} Syntax\n",
    "<b>pyspark.sql.functions.schema_of_json(json, options={})</b>\n",
    "\n",
    "Parses a JSON string and infers its schema in DDL format.\n",
    "\n",
    "Parameters\n",
    "- json – a JSON string or a string literal containing a JSON string.\n",
    "- options – options to control parsing. accepts the same options as the JSON datasource\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legal-thailand",
   "metadata": {},
   "source": [
    "<b>Input:  Spark dataframe containing JSON string column</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "comparative-execution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|jsonstring                                                                                                                                                    |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|{\"me\": {\"name\":\"tony\"},\"myfamily_heirarchy\":{\"myfather\":\"mike\",\"myfather_childs\": [\"me\",\"kent\"],\"my_childs\":{\"name\": \"susan\",\"susan_childs\":{\"name\":\"suzy\"}}}}|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "json_string = '{\"me\": {\"name\":\"tony\"},\"myfamily_heirarchy\":{\"myfather\":\"mike\",\"myfather_childs\": [\"me\",\"kent\"],\"my_childs\":{\"name\": \"susan\",\"susan_childs\":{\"name\":\"suzy\"}}}}'\n",
    "rdd = spark.sparkContext.parallelize([json_string])\n",
    "df_json = spark.createDataFrame([(json_string,)],[\"jsonstring\"])\n",
    "df_json.show(1,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seventh-driving",
   "metadata": {},
   "source": [
    "<b>Output :  Spark dataframe containing individual JSON elements </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "ready-receipt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'struct<me:struct<name:string>,myfamily_heirarchy:struct<my_childs:struct<name:string,susan_childs:struct<name:string>>,myfather:string,myfather_childs:array<string>>>'"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import schema_of_json,col\n",
    "schema = schema_of_json(json_string,  {'allowUnquotedFieldNames':'true'})\n",
    "schema = schema_of_json(json_string)\n",
    "df_json.select(schema.alias(\"schema\")).collect()[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "opposite-journey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'schema_of_json({\"me\": {\"name\":\"tony\"},\"myfamily_heirarchy\":{\"myfather\":\"mike\",\"myfather_childs\": [\"me\",\"kent\"],\"my_childs\":{\"name\": \"susan\",\"susan_childs\":{\"name\":\"suzy\"}}}})'>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-router",
   "metadata": {},
   "source": [
    "<a id='4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "treated-incidence",
   "metadata": {},
   "source": [
    "## 1c. How to extract elements from JSON column ?\n",
    "\n",
    "\n",
    "```{figure} img/chapter11/3.png\n",
    "---\n",
    "align: center\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-longitude",
   "metadata": {},
   "source": [
    "<b>Input:  Spark dataframe containing JSON column</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "independent-tribune",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------------------------+\n",
      "|me    |myfamily_heirarchy                 |\n",
      "+------+-----------------------------------+\n",
      "|[tony]|[[susan, [suzy]], mike, [me, John]]|\n",
      "+------+-----------------------------------+\n",
      "\n",
      "root\n",
      " |-- me: struct (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |-- myfamily_heirarchy: struct (nullable = true)\n",
      " |    |-- my_childs: struct (nullable = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- susan_childs: struct (nullable = true)\n",
      " |    |    |    |-- name: string (nullable = true)\n",
      " |    |-- myfather: string (nullable = true)\n",
      " |    |-- myfather_childs: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "json_string = '{\"me\": {\"name\":\"tony\"},\"myfamily_heirarchy\":{\"myfather\":\"mike\",\"myfather_childs\": [\"me\",\"John\"],\"my_childs\":{\"name\": \"susan\",\"susan_childs\":{\"name\":\"suzy\"}}}}'\n",
    "rdd = spark.sparkContext.parallelize([json_string])\n",
    "df_json = spark.read.json(rdd)\n",
    "df_json.show(1,False)\n",
    "df_json.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-lease",
   "metadata": {},
   "source": [
    "<b>Output :  Spark dataframe containing individual JSON elements </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "million-ivory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>myfather</th>\n",
       "      <th>mybrother</th>\n",
       "      <th>my daughter</th>\n",
       "      <th>my grand daughter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tony</td>\n",
       "      <td>mike</td>\n",
       "      <td>John</td>\n",
       "      <td>susan</td>\n",
       "      <td>suzy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name myfather mybrother my daughter my grand daughter\n",
       "0  tony     mike      John       susan              suzy"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df_json_ele = df_json.select(\"me.name\",\"myfamily_heirarchy.myfather\",col(\"myfamily_heirarchy.myfather_childs\").getItem(1).alias(\"mybrother\"), \n",
    "               col(\"myfamily_heirarchy.my_childs.name\").alias(\"my daughter\"),\n",
    "               col(\"myfamily_heirarchy.my_childs.susan_childs.name\").alias(\"my grand daughter\"))\n",
    "df_json_ele.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fiscal-senior",
   "metadata": {},
   "source": [
    "<b> Summary:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "colored-venezuela",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input                      Output\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>me</th>\n",
       "      <th>myfamily_heirarchy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>(tony,)</td>\n",
       "      <td>((susan, (suzy,)), mike, [me, John])</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">                              <table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>myfather</th>\n",
       "      <th>mybrother</th>\n",
       "      <th>my daughter</th>\n",
       "      <th>my grand daughter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>tony</td>\n",
       "      <td>mike</td>\n",
       "      <td>John</td>\n",
       "      <td>susan</td>\n",
       "      <td>suzy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">                              "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Input                     \",            \"Output\")\n",
    "display_side_by_side(df_json.toPandas(),df_json_ele.toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enabling-orientation",
   "metadata": {},
   "source": [
    "<a id='5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-custom",
   "metadata": {},
   "source": [
    "## 1d. How to convert a data frame to JSON string?\n",
    "\n",
    "\n",
    "```{figure} img/chapter11/4.png\n",
    "---\n",
    "align: center\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "following-johns",
   "metadata": {},
   "source": [
    "Lets first understand the syntax\n",
    "\n",
    "```{admonition} Syntax\n",
    "<b>toJSON(use_unicode=True)</b>\n",
    "\n",
    "Converts a DataFrame into a RDD of string.\n",
    "Each row is turned into a JSON document as one element in the returned RDD.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-exposure",
   "metadata": {},
   "source": [
    "<b>Input:  Spark data frame  </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "golden-initial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+---+------+------+----------+\n",
      "|name|     city|age|smoker|height| birthdate|\n",
      "+----+---------+---+------+------+----------+\n",
      "|John|  Seattle| 60|  true|   1.7|1960-01-01|\n",
      "|Tony|Cupertino| 30| false|   1.8|1990-01-01|\n",
      "|Mike| New York| 40|  true|  1.65|1980-01-01|\n",
      "+----+---------+---+------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_mul = spark.createDataFrame([('John', 'Seattle', 60, True, 1.7, '1960-01-01'), \n",
    "('Tony', 'Cupertino', 30, False, 1.8, '1990-01-01'), \n",
    "('Mike', 'New York', 40, True, 1.65, '1980-01-01')],['name', 'city', 'age', 'smoker','height', 'birthdate'])\n",
    "df_mul.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extreme-amateur",
   "metadata": {},
   "source": [
    "<b>Output :  Spark data frame with a struct column with a new element added </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "configured-mention",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\"name\":\"John\",\"city\":\"Seattle\",\"age\":60,\"smoker\":true,\"height\":1.7,\"birthdate\":\"1960-01-01\"}',\n",
       " '{\"name\":\"Tony\",\"city\":\"Cupertino\",\"age\":30,\"smoker\":false,\"height\":1.8,\"birthdate\":\"1990-01-01\"}',\n",
       " '{\"name\":\"Mike\",\"city\":\"New York\",\"age\":40,\"smoker\":true,\"height\":1.65,\"birthdate\":\"1980-01-01\"}']"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mul.toJSON(use_unicode=True).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "biblical-pollution",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mul.repartition(1).write.json(\"/Users/deepak/Documents/json1.json\",mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "least-drive",
   "metadata": {},
   "source": [
    "<a id='6'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-spare",
   "metadata": {},
   "source": [
    "## 1e. How to convert JSON string column into StructType column?\n",
    "\n",
    "\n",
    "\n",
    "```{figure} img/chapter11/5.png\n",
    "---\n",
    "align: center\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-placement",
   "metadata": {},
   "source": [
    "Lets first understand the syntax\n",
    "\n",
    "```{admonition} Syntax\n",
    "<b>pyspark.sql.functions.from_json(col, schema, options={})</b>\n",
    "\n",
    "Parses a column containing a JSON string into a MapType with StringType as keys type, StructType or ArrayType with the specified schema. Returns null, in the case of an unparseable string.\n",
    "\n",
    "\n",
    "Parameters\n",
    "- col – string column in json format\n",
    "- schema – a StructType or ArrayType of StructType to use when parsing the json column.\n",
    "options – options to control parsing. accepts the same options as the json datasource\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-origin",
   "metadata": {},
   "source": [
    "<b>Input:  Spark data frame with a JSON string column  </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "korean-entity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|jsonstring               |\n",
      "+-------------------------+\n",
      "|{\"name\": \"tony\",\"id\":111}|\n",
      "+-------------------------+\n",
      "\n",
      "root\n",
      " |-- jsonstring: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "data = [('{\"name\": \"tony\",\"id\":111}',)]\n",
    "schema1 = StructType([StructField(\"name\", StringType()), StructField(\"id\", IntegerType())])\n",
    "schema2 = \"name string, id int\"\n",
    "df = spark.createDataFrame(data, [\"jsonstring\"])\n",
    "df.show(1,False)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-welding",
   "metadata": {},
   "source": [
    "<b>Output :  Spark data frame with a struct column </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "rural-sudan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|     struct|\n",
      "+-----------+\n",
      "|[tony, 111]|\n",
      "+-----------+\n",
      "\n",
      "root\n",
      " |-- struct: struct (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import from_json\n",
    "df_stru = df.select(from_json(df.jsonstring, schema1).alias(\"struct\"))\n",
    "\n",
    "df.select(from_json(df.jsonstring, schema2).alias(\"struct\")).show()\n",
    "df_stru.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "seven-vampire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|to_json(struct)         |\n",
      "+------------------------+\n",
      "|{\"name\":\"tony\",\"id\":111}|\n",
      "+------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('to_json(struct)', 'string')]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_json\n",
    "df_jsonstroing = df_stru.select(to_json(df_stru.struct))\n",
    "df_jsonstroing.show(1, False)\n",
    "df_stru.select(to_json(df_stru.struct)).dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heated-scotland",
   "metadata": {},
   "source": [
    "<b> Summary:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "future-slide",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input                      output\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>jsonstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>{\"name\": \"tony\",\"id\":111}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">                              <table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>struct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>(tony, 111)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">                              "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"input                     \",            \"output\")\n",
    "display_side_by_side(df.toPandas(),df.select(from_json(df.jsonstring, schema1).alias(\"struct\")).toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-homework",
   "metadata": {},
   "source": [
    "<a id='7'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catholic-monday",
   "metadata": {},
   "source": [
    "## 1f. How to convert JSON string column into MapType column?\n",
    "\n",
    "\n",
    "\n",
    "```{figure} img/chapter11/6.png\n",
    "---\n",
    "align: center\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-indonesia",
   "metadata": {},
   "source": [
    "<b>Input:  Spark data frame with a JSON string column </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "hearing-anchor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|jsonstring               |\n",
      "+-------------------------+\n",
      "|{\"name\": \"tony\",\"id\":111}|\n",
      "+-------------------------+\n",
      "\n",
      "root\n",
      " |-- jsonstring: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "data = [('{\"name\": \"tony\",\"id\":111}',)]\n",
    "schema = StructType([StructField(\"name\", StringType()), StructField(\"id\", IntegerType())])\n",
    "df = spark.createDataFrame(data, [ \"jsonstring\"])\n",
    "df.show(1,False)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frequent-exchange",
   "metadata": {},
   "source": [
    "<b>Output :  Spark dataframe with a MapType column</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "alternate-defensive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|MapType                  |\n",
      "+-------------------------+\n",
      "|[name -> tony, id -> 111]|\n",
      "+-------------------------+\n",
      "\n",
      "root\n",
      " |-- MapType: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_map = df.select(from_json(df.jsonstring, \"MAP<string,string>\").alias(\"MapType\"))\n",
    "df_map.show(1,False)\n",
    "df_map.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prime-signature",
   "metadata": {},
   "source": [
    "<b> Summary:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "large-country",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input                      Output\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>jsonstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>{\"name\": \"tony\",\"id\":111}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">                              <table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>MapType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>{'name': 'tony', 'id': '111'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">                              "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('jsonstring', 'string')] [('MapType', 'map<string,string>')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Input                     \",            \"Output\")\n",
    "display_side_by_side(df.toPandas(),df_map.toPandas())\n",
    "print(df.dtypes,df_map.dtypes)                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-milan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "limited-consultancy",
   "metadata": {},
   "source": [
    "<a id='8'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reliable-johns",
   "metadata": {},
   "source": [
    "## 1g. How to convert JSON string column into ArrayType column?\n",
    "\n",
    "\n",
    "\n",
    "```{figure} img/chapter1/7.png\n",
    "---\n",
    "align: center\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reasonable-preview",
   "metadata": {},
   "source": [
    "<b>Input:  Spark data frame with a JSON string column </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "diverse-organ",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "|jsonstring                 |\n",
      "+---------------------------+\n",
      "|[{\"name\": \"tony\",\"id\":111}]|\n",
      "+---------------------------+\n",
      "\n",
      "root\n",
      " |-- jsonstring: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "data = [('[{\"name\": \"tony\",\"id\":111}]',)]\n",
    "schema = StructType([StructField(\"name\", StringType()), StructField(\"id\", IntegerType())])\n",
    "df = spark.createDataFrame(data, [ \"jsonstring\"])\n",
    "df.show(1,False)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-result",
   "metadata": {},
   "source": [
    "<b>Output :  Spark dataframe with a ArrayType column</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "severe-messaging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|ArrayType    |\n",
      "+-------------+\n",
      "|[[tony, 111]]|\n",
      "+-------------+\n",
      "\n",
      "root\n",
      " |-- ArrayType: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = ArrayType(StructType([StructField(\"name\", StringType()), StructField(\"id\", IntegerType())]))\n",
    "df_arr = df.select(from_json(df.jsonstring, schema).alias(\"ArrayType\"))\n",
    "df_arr.show(1,False)\n",
    "df_arr.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "searching-yield",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|ArrayType    |\n",
      "+-------------+\n",
      "|[[tony, 111]]|\n",
      "+-------------+\n",
      "\n",
      "root\n",
      " |-- ArrayType: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- id: integer (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "schema = ArrayType(StructType([StructField(\"name\", StringType()), StructField(\"id\", IntegerType())]))\n",
    "df_arr = df.select(from_json(df.jsonstring, schema).alias(\"ArrayType\"))\n",
    "df_arr.show(1,False)\n",
    "print(df_arr.printSchema())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-union",
   "metadata": {},
   "source": [
    "<b> Summary:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "external-collection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input                      Output\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>jsonstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>[{\"name\": \"tony\",\"id\":111}]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">                              <table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ArrayType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>[(tony, 111)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">                              "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('jsonstring', 'string')] [('ArrayType', 'array<struct<name:string,id:int>>')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Input                     \",            \"Output\")\n",
    "display_side_by_side(df.toPandas(),df_arr.toPandas())\n",
    "print(df.dtypes,df_arr.dtypes)                    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-twist",
   "metadata": {},
   "source": [
    "<a id='9'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attended-korean",
   "metadata": {},
   "source": [
    "## 1h. How to convert StructType/MapType/ArrayType  column into JSON string?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-peace",
   "metadata": {},
   "source": [
    "```{figure} img/chapter11/8.png\n",
    "---\n",
    "align: center\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-pipeline",
   "metadata": {},
   "source": [
    "Lets first understand the syntax\n",
    "\n",
    "```{admonition} Syntax\n",
    "<b>pyspark.sql.functions.to_json(col, options={})</b>\n",
    "\n",
    "Converts a column containing a StructType, ArrayType or a MapType into a JSON string. Throws an exception, in the case of an unsupported type.\n",
    "\n",
    "Parameters\n",
    "- col – name of column containing a struct, an array or a map.\n",
    "- options – options to control converting. accepts the same options as the JSON datasource. Additionally the function supports the pretty option which enables pretty JSON generation.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tropical-intake",
   "metadata": {},
   "source": [
    "<b>Input :  Spark data frame with a struct column </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "comparable-ordering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+\n",
      "|ArrayofMap                      |\n",
      "+--------------------------------+\n",
      "|[[name -> Alice], [name -> Bob]]|\n",
      "+--------------------------------+\n",
      "\n",
      "root\n",
      " |-- ArrayofMap: array (nullable = true)\n",
      " |    |-- element: map (containsNull = true)\n",
      " |    |    |-- key: string\n",
      " |    |    |-- value: string (valueContainsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [([{\"name\": \"Alice\"}, {\"name\": \"Bob\"}],)]\n",
    "df = spark.createDataFrame(data, [\"ArrayofMap\"])\n",
    "df.show(1,False)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "olympic-regression",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+\n",
      "|json                             |\n",
      "+---------------------------------+\n",
      "|[{\"name\":\"Alice\"},{\"name\":\"Bob\"}]|\n",
      "+---------------------------------+\n",
      "\n",
      "root\n",
      " |-- json: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_json\n",
    "df.select(to_json(df.ArrayofMap).alias(\"json\")).show(1,False)\n",
    "df.select(to_json(df.ArrayofMap).alias(\"json\")).printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flush-consumer",
   "metadata": {},
   "source": [
    "<b> Summary:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "quick-species",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input                      output\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ArrayofMap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>[{'name': 'Alice'}, {'name': 'Bob'}]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">                              <table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>[{\"name\":\"Alice\"},{\"name\":\"Bob\"}]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">                              "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"input                     \",            \"output\")\n",
    "display_side_by_side(df.toPandas(),df.select(to_json(df.ArrayofMap).alias(\"json\")).toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environmental-gothic",
   "metadata": {},
   "source": [
    "<a id='10'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaning-passenger",
   "metadata": {},
   "source": [
    "## 1i. How to extract JSON object from a JSON  string column?\n",
    "\n",
    "\n",
    "\n",
    "```{figure} img/chapter11/9.png\n",
    "---\n",
    "align: center\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-makeup",
   "metadata": {},
   "source": [
    "Lets first understand the syntax\n",
    "\n",
    "```{admonition} Syntax\n",
    "<b>pyspark.sql.functions.get_json_object(col, path)</b>\n",
    "\n",
    "Extracts json object from a json string based on json path specified, and returns json string of the extracted json object. It will return null if the input json string is invalid.\n",
    "\n",
    "Parameters\n",
    "- col – string column in json format\n",
    "- path – path to the json object to extract\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-seafood",
   "metadata": {},
   "source": [
    "<b>Input:  Spark data frame with a JSON string column </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "dynamic-sheep",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|jsonstring                                                                                                                                                    |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|{\"me\": {\"name\":\"tony\"},\"myfamily_heirarchy\":{\"myfather\":\"mike\",\"myfather_childs\": [\"me\",\"John\"],\"my_childs\":{\"name\": \"susan\",\"susan_childs\":{\"name\":\"suzy\"}}}}|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "json_string = '{\"me\": {\"name\":\"tony\"},\"myfamily_heirarchy\":{\"myfather\":\"mike\",\"myfather_childs\": [\"me\",\"John\"],\"my_childs\":{\"name\": \"susan\",\"susan_childs\":{\"name\":\"suzy\"}}}}'\n",
    "df_json = spark.createDataFrame([(json_string,)],[\"jsonstring\"])\n",
    "df_json.show(1,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considered-issue",
   "metadata": {},
   "source": [
    "<b>Output :  Spark dataframe with column containing a JSON object</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "certified-humor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|jsonobject|\n",
      "+----------+\n",
      "|suzy      |\n",
      "+----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('jsonobject', 'string')]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import get_json_object\n",
    "df_obj = df_json.select(get_json_object(df_json.jsonstring  , \"$.myfamily_heirarchy.my_childs.susan_childs.name\").alias(\"jsonobject\"))\n",
    "df_obj.show(1,False)\n",
    "df_obj.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-deviation",
   "metadata": {},
   "source": [
    "<b> Summary:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "fixed-motel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input                      Output\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>jsonstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>{\"me\": {\"name\":\"tony\"},\"myfamily_heirarchy\":{\"myfather\":\"mike\",\"myfather_childs\": [\"me\",\"John\"],\"my_childs\":{\"name\": \"susan\",\"susan_childs\":{\"name\":\"suzy\"}}}}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">                              <table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>jsonobject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>suzy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">                              "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Input                     \",            \"Output\")\n",
    "display_side_by_side(df_json.toPandas(),df_obj.toPandas())\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identified-thailand",
   "metadata": {},
   "source": [
    "<a id='11'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-transaction",
   "metadata": {},
   "source": [
    "## 1j. How to extract JSON objects based on list of field names?\n",
    "\n",
    "\n",
    "\n",
    "```{figure} img/chapter11/10.png\n",
    "---\n",
    "align: center\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-prize",
   "metadata": {},
   "source": [
    "Lets first understand the syntax\n",
    "\n",
    "```{admonition} Syntax\n",
    "<b>pyspark.sql.functions.json_tuple(col, *fields)</b>\n",
    "\n",
    "Creates a new row for a json column according to the given field names.\n",
    "\n",
    "Parameters\n",
    "\n",
    "- col – string column in json format\n",
    "- fields – list of fields to extract\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italian-kazakhstan",
   "metadata": {},
   "source": [
    "<b>Input:  Spark data frame with a JSON string column </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "frequent-irish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|jsonstring                                                                                                                                                    |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|{\"me\": {\"name\":\"tony\"},\"myfamily_heirarchy\":{\"myfather\":\"mike\",\"myfather_childs\": [\"me\",\"John\"],\"my_childs\":{\"name\": \"susan\",\"susan_childs\":{\"name\":\"suzy\"}}}}|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "json_string = '{\"me\": {\"name\":\"tony\"},\"myfamily_heirarchy\":{\"myfather\":\"mike\",\"myfather_childs\": [\"me\",\"John\"],\"my_childs\":{\"name\": \"susan\",\"susan_childs\":{\"name\":\"suzy\"}}}}'\n",
    "df_json = spark.createDataFrame([(json_string,)],[\"jsonstring\"])\n",
    "df_json.show(1,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stunning-tyler",
   "metadata": {},
   "source": [
    "<b>Output :  Spark dataframe with a MapType column</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "impossible-flavor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------------------------------------------------------------------------------------------------------+\n",
      "|c0             |c1                                                                                                             |\n",
      "+---------------+---------------------------------------------------------------------------------------------------------------+\n",
      "|{\"name\":\"tony\"}|{\"myfather\":\"mike\",\"myfather_childs\":[\"me\",\"John\"],\"my_childs\":{\"name\":\"susan\",\"susan_childs\":{\"name\":\"suzy\"}}}|\n",
      "+---------------+---------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import json_tuple\n",
    "df_out = df_json.select(json_tuple(df_json.jsonstring, 'me', 'myfamily_heirarchy',))\n",
    "df_out.show(1,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-judge",
   "metadata": {},
   "source": [
    "<b> Summary:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "detailed-evidence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input                      Output\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>jsonstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>{\"me\": {\"name\":\"tony\"},\"myfamily_heirarchy\":{\"myfather\":\"mike\",\"myfather_childs\": [\"me\",\"John\"],\"my_childs\":{\"name\": \"susan\",\"susan_childs\":{\"name\":\"suzy\"}}}}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">                              <table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>{\"name\":\"tony\"}</td>\n",
       "      <td>{\"myfather\":\"mike\",\"myfather_childs\":[\"me\",\"John\"],\"my_childs\":{\"name\":\"susan\",\"susan_childs\":{\"name\":\"suzy\"}}}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">                              "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Input                     \",            \"Output\")\n",
    "display_side_by_side(df_json.toPandas(),df_out.toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-decimal",
   "metadata": {},
   "source": [
    "<a id='9'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-anchor",
   "metadata": {},
   "source": [
    "<a id='9'></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
